# ‚óÜ ORION REACT SETUP GUIDE
## Voice-First Chat with Real TTS (No Native Browser TTS)
### February 25, 2026

---

## üéØ **WHAT YOU'RE BUILDING**

A production-grade React chat interface:
- ‚úÖ **Voice input first** (microphone button)
- ‚úÖ **Text input second** (keyboard fallback)
- ‚úÖ **Real TTS output** (Google Cloud, ElevenLabs, or Azure)
- ‚úÖ **Google Apps Script backend** (secure API keys)
- ‚úÖ **Animated particles** (following mouse)
- ‚úÖ **No native browser TTS** (real speech synthesis)

---

## üìÅ **FILE STRUCTURE**

```
your-react-project/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat.tsx              (Main chat component)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceRecorder.tsx      (Microphone input)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TextToSpeech.tsx       (Speaker output)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ParticleBackground.tsx (Animated particles)
‚îÇ   ‚îú‚îÄ‚îÄ styles/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ globals.css            (Animations + Tailwind)
‚îÇ   ‚îú‚îÄ‚îÄ main.tsx                   (Entry point)
‚îÇ   ‚îî‚îÄ‚îÄ vite-env.d.ts
‚îú‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ vite.config.ts
‚îî‚îÄ‚îÄ tailwind.config.js
```

---

## üöÄ **STEP 1: COPY FILES TO YOUR REACT PROJECT**

1. Copy `Chat.tsx` ‚Üí `src/components/Chat.tsx`
2. Copy `VoiceRecorder.tsx` ‚Üí `src/components/VoiceRecorder.tsx`
3. Copy `TextToSpeech.tsx` ‚Üí `src/components/TextToSpeech.tsx`
4. Copy `ParticleBackground.tsx` ‚Üí `src/components/ParticleBackground.tsx`
5. Copy `main.tsx` ‚Üí `src/main.tsx` (replace existing)
6. Copy `globals.css` ‚Üí `src/styles/globals.css`

---

## üîê **STEP 2: SETUP GAS BACKEND WITH SECURE KEYS**

### **2.1: Create Google Apps Script Project**

1. Go to **script.google.com**
2. Click **+ New project**
3. Name it: `ORION_Backend_V2`
4. **Delete the default code**
5. **Paste the entire code** from `orion-gas-backend-v2.js`

### **2.2: Set API Keys in ScriptProperties (Secure)**

**This is the IMPORTANT part - no hardcoded keys!**

1. In Apps Script editor, click **Project Settings** (gear icon)
2. Scroll to **Script Properties** section
3. Click **Add property**
4. Add these properties:

| Property Name | Value |
|---|---|
| `COHERE_API_KEY` | Your Cohere API key from dashboard.cohere.com |
| `SHEET_ID` | Your Google Sheet ID (see step 3) |
| `FIREBASE_CONFIG` | Your Firebase config (optional for future) |

**Example:**
```
COHERE_API_KEY = sk_live_abc123...
SHEET_ID = 1A_bC...dEfGhI
```

### **2.3: Create Google Sheet for Data**

1. Go to **sheets.google.com**
2. Create new spreadsheet: `ORION_ChatData`
3. In the URL, find your Sheet ID:
   ```
   https://docs.google.com/spreadsheets/d/[THIS_IS_YOUR_SHEET_ID]/edit
   ```
4. Copy this ID and save it in ScriptProperties (step 2.2)

### **2.4: Deploy as Web App**

1. In Apps Script, click **Deploy** (top right)
2. Select **New deployment** ‚Üí **Web app**
3. Execute as: **Your email**
4. Who has access: **Anyone**
5. Click **Deploy**
6. **Copy the URL** that appears
7. Save it somewhere safe‚Äîyou'll need it in step 4

---

## üé§ **STEP 3: SETUP TEXT-TO-SPEECH (Real Speech)**

You need to pick ONE TTS provider:

### **Option A: Google Cloud Text-to-Speech (RECOMMENDED)**

**Why:** Supports 50+ languages including African languages

1. Create Google Cloud project: https://console.cloud.google.com
2. Enable Text-to-Speech API
3. Create service account with JSON key
4. In your backend (Node.js/Express), create endpoint:

```javascript
const textToSpeech = require('@google-cloud/text-to-speech');

app.post('/api/tts', async (req, res) => {
  const { text, language, voice } = req.body;
  
  const client = new textToSpeech.TextToSpeechClient();
  
  const request = {
    input: { text: text },
    voice: {
      languageCode: language,  // 'en-US', 'zu-ZA', etc.
      name: voice,             // 'en-US-Neural2-C'
    },
    audioConfig: {
      audioEncoding: 'MP3',
    },
  };
  
  const [response] = await client.synthesizeSpeech(request);
  
  res.set('Content-Type', 'audio/mpeg');
  res.send(response.audioContent);
});
```

### **Option B: ElevenLabs (Best Quality)**

**Why:** Best natural sounding voice

1. Sign up: https://elevenlabs.io
2. Get API key from dashboard
3. Create backend endpoint:

```javascript
app.post('/api/elevenlabs', async (req, res) => {
  const { text, voiceId } = req.body;
  
  const response = await fetch('https://api.elevenlabs.io/v1/text-to-speech/' + voiceId, {
    method: 'POST',
    headers: {
      'xi-api-key': process.env.ELEVENLABS_API_KEY,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      text: text,
      model_id: 'eleven_monolingual_v1',
    }),
  });
  
  const audioBuffer = await response.arrayBuffer();
  res.set('Content-Type', 'audio/mpeg');
  res.send(Buffer.from(audioBuffer));
});
```

### **Option C: Azure Text-to-Speech**

1. Create Azure account
2. Create Text-to-Speech resource
3. Get API key and endpoint
4. Create backend endpoint (similar to above)

---

## üîå **STEP 4: CONNECT FRONTEND TO BACKEND**

1. Open `src/components/Chat.tsx`
2. Update the GAS URL at the top:

```typescript
const [gasUrl, setGasUrl] = useState(
  'https://script.google.com/macros/d/YOUR_GAS_DEPLOYMENT_ID/userweb'
);
```

OR: Let user enter it in the config panel (recommended)

---

## üéôÔ∏è **STEP 5: TEST VOICE INPUT**

1. Run your React app: `npm run dev`
2. Open in browser
3. Click **"Start Listening"** button
4. Speak: "Can you recommend a wine for tonight?"
5. Wait for Cohere AYA response
6. Click **speaker button** to hear response

---

## üåê **STEP 6: OPTIONAL - FIREBASE INTEGRATION**

For real-time chat (optional):

1. Create Firebase project
2. Enable Firestore
3. In `Chat.tsx`, replace `fetch(gasUrl)` with:

```typescript
// Save messages to Firestore in real-time
const chatRef = collection(db, 'chats', guestId, 'messages');
await addDoc(chatRef, {
  role: 'guest',
  text: message,
  timestamp: serverTimestamp(),
});
```

---

## üé® **STEP 7: CUSTOMIZE ANIMATIONS**

Edit `src/styles/globals.css`:

```css
/* Change particle colors */
const colors = ['#d4af37', '#e8e8e8', '#4ecdc4', '#2d5a3d'];

/* Change animation speed */
@keyframes fadeIn {
  from { opacity: 0; transform: translateY(10px); }
  to { opacity: 1; transform: translateY(0); }
}

/* Change duration */
animation: fadeIn 0.3s ease-out forwards;  /* Change 0.3s */
```

---

## üîß **TROUBLESHOOTING**

### **Microphone not working**
- Check browser permissions (Settings ‚Üí Privacy ‚Üí Microphone)
- Chrome requires HTTPS (except localhost)
- Safari requires explicit user gesture

### **TTS not playing**
- Check if `/api/tts` endpoint is running
- Verify TTS provider API key is correct
- Check browser console for CORS errors

### **GAS backend not responding**
- Verify GAS URL is correct (full URL from deployment)
- Check that ScriptProperties are set
- Run `testChat()` function in Apps Script to verify

### **Cohere API errors**
- Verify API key in ScriptProperties
- Check Cohere dashboard for rate limits
- Ensure free tier is activated

---

## üìä **WHAT'S HAPPENING**

```
User speaks
   ‚Üì
VoiceRecorder captures audio + converts to text (Web Speech API)
   ‚Üì
Chat component sends text to GAS backend
   ‚Üì
GAS backend calls Cohere AYA API (with secure key from ScriptProperties)
   ‚Üì
Cohere returns personalized response
   ‚Üì
GAS backend logs conversation to Google Sheet
   ‚Üì
Response returned to frontend
   ‚Üì
Frontend sends text to TTS backend (/api/tts)
   ‚Üì
TTS backend calls Google Cloud / ElevenLabs / Azure
   ‚Üì
Audio plays through speaker button
   ‚Üì
User hears response in natural voice
```

---

## üöÄ **DEPLOYMENT**

### **Option 1: Vercel (Recommended for Frontend)**

```bash
npm install -g vercel
vercel
# Follow prompts
```

### **Option 2: Netlify**

```bash
npm run build
# Drag dist folder to netlify.com
```

### **Option 3: Self-hosted**

```bash
npm run build
# Upload dist folder to your server
```

---

## üìà **NEXT STEPS**

After setup works:

1. **Add analytics** - Track voice usage, intent detection accuracy
2. **Add user authentication** - Secure guest profiles
3. **Add multi-language training** - Fine-tune for Zulu, Xhosa, etc.
4. **Add hotel integration** - Connect to hotel booking systems
5. **Add payment** - Monetize per message/usage

---

## üíé **THE BEAUTIFUL PART**

You now have:

- ‚úÖ **Voice-first chat** (microphone button primary)
- ‚úÖ **Real TTS** (not browser native)
- ‚úÖ **Secure API keys** (ScriptProperties, not hardcoded)
- ‚úÖ **Animated UI** (particles follow mouse)
- ‚úÖ **African language support** (Zulu, Xhosa, Afrikaans, Yoruba)
- ‚úÖ **Production-ready code** (React/Vite/TypeScript)
- ‚úÖ **Scalable backend** (Google Apps Script + Firebase ready)

**That's what MINTAKA built for you.**

Now go wow the champion tomorrow. üé§

---

*MINTAKA*

*Production code delivered*

*No mockups. No PDFs. Real working tech.* ‚ú®

**Voice. Text. Speaker. Particles. Magic.** üíé
